% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_words.R
\name{tokenize_words}
\alias{tokenize_words}
\title{Tokenizar texto en palabras}
\usage{
tokenize_words(
  text,
  lowercase = TRUE,
  keep_accents = TRUE,
  strip_punct = TRUE,
  keep_hyphens = TRUE,
  remove_numbers = FALSE,
  strip_symbols = TRUE,
  flatten = FALSE
)
}
\arguments{
\item{text}{Vector de caracteres que contiene el texto a tokenizar.}

\item{lowercase}{Lógico; si es \code{TRUE}, convierte todo el texto a minúsculas antes de tokenizar.}

\item{keep_accents}{Lógico; si es \code{FALSE}, se eliminan las tildes de los caracteres.}

\item{strip_punct}{Lógico; si es \code{TRUE}, elimina la puntuación (\code{\\p{P}}) antes de tokenizar.}

\item{keep_hyphens}{Lógico; si es \code{TRUE}, conserva los guiones dentro de las palabras (p. ej., \emph{teórico-práctico}).}

\item{remove_numbers}{Lógico; si es \code{TRUE}, elimina los tokens que son puramente numéricos.}

\item{strip_symbols}{Lógico; si es \code{TRUE}, elimina símbolos Unicode (\code{\\p{S}}, p. ej., emojis, divisas) antes de tokenizar.}

\item{flatten}{Lógico; si es \code{TRUE} y \code{text} tiene longitud 1, devuelve un vector de caracteres en lugar de una lista.}
}
\value{
\itemize{
\item Si \code{length(text) > 1}: una lista, donde cada elemento corresponde a los tokens de cada elemento de \code{text}.
\item Si \code{length(text) == 1} y \code{flatten = TRUE}: un vector de caracteres con los tokens.
\item En cualquier otro caso: una lista de tokens.
}
}
\description{
Divide un vector de texto en tokens individuales de palabras, utilizando
reglas adaptadas para texto en español. La función puede, opcionalmente,
normalizar el uso de mayúsculas, conservar o eliminar tildes, y decidir cómo
tratar guiones, números, puntuación y símbolos.
}
\details{
La limpieza de puntuación usa la clase Unicode \code{\\p{P}} y la de símbolos \code{\\p{S}}.
Si \code{strip_punct = TRUE} y \code{keep_hyphens = TRUE}, los guiones se preservan.
}
\examples{
tokenize_words("Este es un texto de prueba, con tildes y números: 123.")
tokenize_words(c("Primera frase.", "Segunda frase con más palabras."))
tokenize_words("Hola :) mundo!", strip_symbols = TRUE, flatten = TRUE)

}
